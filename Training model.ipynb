{"cells":[{"cell_type":"markdown","metadata":{"id":"QUANWN3rpfC9"},"source":["# Подготовка модели, обучение и тестирование"]},{"cell_type":"markdown","metadata":{"id":"Un75hNW1ZQfM"},"source":["## 0. Организуем структуру проекта"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":390,"status":"ok","timestamp":1650314294296,"user":{"displayName":"Александр","userId":"07878979912285210689"},"user_tz":-180},"id":"146BB11JpfDA"},"outputs":[],"source":["import os"]},{"cell_type":"markdown","metadata":{"id":"Zrx799niZQfP"},"source":["### Имя модели и URL берем с сайта \n","https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1650314294603,"user":{"displayName":"Александр","userId":"07878979912285210689"},"user_tz":-180},"id":"42hJEdo_pfDB"},"outputs":[],"source":["CUSTOM_MODEL_NAME = 'my_ssd_mobilenet' \n","PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8'\n","PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz'\n","TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n","LABEL_MAP_NAME = 'label_map.pbtxt'"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1650314294923,"user":{"displayName":"Александр","userId":"07878979912285210689"},"user_tz":-180},"id":"hbPhYVy_pfDB"},"outputs":[],"source":["# Словарь path поможет вдальнейшем для сокращения и удобочитаемости кода\n","paths = {\n","    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n","    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n","    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n","    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n","    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n","    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n","    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n","    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n","    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n","    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n","    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n","    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n"," }"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1650314294925,"user":{"displayName":"Александр","userId":"07878979912285210689"},"user_tz":-180},"id":"LwhWZMI0pfDC"},"outputs":[],"source":["files = {\n","    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n","    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n","    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n","}"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1650314294927,"user":{"displayName":"Александр","userId":"07878979912285210689"},"user_tz":-180},"id":"HR-TfDGrpfDC"},"outputs":[],"source":["# Создаем все вышеуказанные пути если они еще не созданы\n","for path in paths.values():\n","    if not os.path.exists(path):\n","        if os.name == 'posix':\n","            !mkdir -p {path}\n","        if os.name == 'nt':\n","            !mkdir {path}"]},{"cell_type":"markdown","metadata":{"id":"OLU-rs_ipfDE"},"source":["## 1. Скачиваем модель из Tensorflow Model Zoo и устанавливаем ее"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1650314295948,"user":{"displayName":"Александр","userId":"07878979912285210689"},"user_tz":-180},"id":"SatcUcqm1Ug7"},"outputs":[],"source":["# https://www.tensorflow.org/install/source_windows"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1650314296805,"user":{"displayName":"Александр","userId":"07878979912285210689"},"user_tz":-180},"id":"K-Cmz2edpfDE","scrolled":true},"outputs":[],"source":["# Библиотека необходима в Windows для загрузки protobuf\n","if os.name=='nt':\n","    !pip install wget \n","    import wget"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24833,"status":"ok","timestamp":1650314322640,"user":{"displayName":"Александр","userId":"07878979912285210689"},"user_tz":-180},"id":"iA1DIq5OpfDE","outputId":"b89c5a62-ae93-4e5c-91dd-f31af49865d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Tensorflow/models'...\n","remote: Enumerating objects: 71938, done.\u001b[K\n","remote: Total 71938 (delta 0), reused 0 (delta 0), pack-reused 71938\u001b[K\n","Receiving objects: 100% (71938/71938), 578.93 MiB | 27.00 MiB/s, done.\n","Resolving deltas: 100% (50893/50893), done.\n"]}],"source":["# Клонируем выбранные модели\n","if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n","    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"rJjMHbnDs3Tv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650314378775,"user_tz":-180,"elapsed":56145,"user":{"displayName":"Александр","userId":"07878979912285210689"}},"outputId":"872d3545-8b3f-4914-fb71-8d4ee9091611"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n","0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n","Processing /content/Tensorflow/models/research\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Collecting avro-python3\n","  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n","Collecting apache-beam\n","  Downloading apache_beam-2.37.0-cp37-cp37m-manylinux2010_x86_64.whl (10.1 MB)\n","\u001b[K     |████████████████████████████████| 10.1 MB 8.4 MB/s \n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.28)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n","Collecting tf-slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","\u001b[K     |████████████████████████████████| 352 kB 12.3 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n","Collecting lvis\n","  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n","Collecting tf-models-official>=2.5.1\n","  Downloading tf_models_official-2.8.0-py2.py3-none-any.whl (2.2 MB)\n","\u001b[K     |████████████████████████████████| 2.2 MB 39.9 MB/s \n","\u001b[?25hCollecting tensorflow_io\n","  Downloading tensorflow_io-0.24.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.4 MB)\n","\u001b[K     |████████████████████████████████| 23.4 MB 47.2 MB/s \n","\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.8.0)\n","Collecting opencv-python-headless\n","  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n","\u001b[K     |████████████████████████████████| 47.8 MB 52 kB/s \n","\u001b[?25hCollecting pyyaml<6.0,>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 40.8 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Collecting py-cpuinfo>=3.3.0\n","  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n","\u001b[K     |████████████████████████████████| 99 kB 8.4 MB/s \n","\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n","Requirement already satisfied: tensorflow~=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n","Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 34.6 MB/s \n","\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n","\u001b[K     |████████████████████████████████| 90 kB 9.2 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 38.1 MB/s \n","\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n","  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n","\u001b[K     |████████████████████████████████| 237 kB 47.4 MB/s \n","\u001b[?25hCollecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.5)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n","Collecting tensorflow-text~=2.8.0\n","  Downloading tensorflow_text-2.8.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[K     |████████████████████████████████| 4.9 MB 20.2 MB/s \n","\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n","Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.31.5)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2018.9)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.0)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.1)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.8)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (13.0.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.5.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.24.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n","Collecting tf-estimator-nightly==2.8.0.dev2021122109\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 46.2 MB/s \n","\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.44.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.6)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n","Collecting hdfs<3.0.0,>=2.1.0\n","  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n","Collecting orjson<4.0\n","  Downloading orjson-3.6.8-cp37-cp37m-manylinux_2_24_x86_64.whl (253 kB)\n","\u001b[K     |████████████████████████████████| 253 kB 33.2 MB/s \n","\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Collecting proto-plus<2,>=1.7.1\n","  Downloading proto_plus-1.20.3-py3-none-any.whl (46 kB)\n","\u001b[K     |████████████████████████████████| 46 kB 3.5 MB/s \n","\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Collecting dill<0.3.2,>=0.3.1.1\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 46.4 MB/s \n","\u001b[?25hCollecting cloudpickle<3,>=2.0.0\n","  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n","Collecting pymongo<4.0.0,>=3.8.0\n","  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n","\u001b[K     |████████████████████████████████| 508 kB 42.2 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow<7.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n","Collecting requests<3.0.0dev,>=2.18.0\n","  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n","\u001b[?25hCollecting fastavro<2,>=0.23.6\n","  Downloading fastavro-1.4.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","\u001b[K     |████████████████████████████████| 2.3 MB 34.0 MB/s \n","\u001b[?25hRequirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n","Collecting protobuf>=3.12.0\n","  Downloading protobuf-3.20.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n","\u001b[K     |████████████████████████████████| 1.0 MB 38.4 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.12)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.2)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n","Collecting portalocker\n","  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.6.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.7.0)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n","Building wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, seqeval\n","  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1690985 sha256=14256a4bd69c608e1d619a779ba32883c589f9997de9a9fb3389d2a7aa5e5a0f\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-stsi6pi9/wheels/a9/26/bf/1cb2313ed4855917889b97658bf0a19999e3588e47867bdaee\n","  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=06146cfc2e311136b016f109a10d41312cdd93df21b849ffe7597ae0cb9d6478\n","  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n","  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=536ece46bb7f6b4f533bef562b2fe33948b515be08512abb40794b88e3a07e87\n","  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n","  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=5c319fc42ddf67d94c00c64d2a2886d3c74d7edae4a9cf1274233668a734cc13\n","  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=ada25e5856b992cfe771e15ae544229a486ac4f626ece10833ae98672ab6e0a6\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built object-detection py-cpuinfo dill avro-python3 seqeval\n","Installing collected packages: requests, protobuf, tf-estimator-nightly, portalocker, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.17.3\n","    Uninstalling protobuf-3.17.3:\n","      Successfully uninstalled protobuf-3.17.3\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.4\n","    Uninstalling dill-0.3.4:\n","      Successfully uninstalled dill-0.3.4\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: pymongo\n","    Found existing installation: pymongo 4.1.0\n","    Uninstalling pymongo-4.1.0:\n","      Successfully uninstalled pymongo-4.1.0\n","  Attempting uninstall: cloudpickle\n","    Found existing installation: cloudpickle 1.3.0\n","    Uninstalling cloudpickle-1.3.0:\n","      Successfully uninstalled cloudpickle-1.3.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n","gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed apache-beam-2.37.0 avro-python3-1.10.2 cloudpickle-2.0.0 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.10 hdfs-2.7.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.5.64 orjson-3.6.8 portalocker-2.4.0 proto-plus-1.20.3 protobuf-3.20.0 py-cpuinfo-8.0.0 pymongo-3.12.3 pyyaml-5.4.1 requests-2.27.1 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.16.1 tensorflow-io-0.24.0 tensorflow-model-optimization-0.7.2 tensorflow-text-2.8.1 tf-estimator-nightly-2.8.0.dev2021122109 tf-models-official-2.8.0 tf-slim-1.1.0\n"]}],"source":["# Устанавливаем Tensorflow Object Detection \n","# Библиотека позволяет дообучать предобученные модели\n","# Для коректной работы обучения необходим дополнительный модуль protobuf\n","if os.name=='posix':  \n","    !apt-get install protobuf-compiler\n","    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n","    \n","if os.name=='nt':\n","    if not os.path.exists(os.path.join(paths['PROTOC_PATH'], 'bin')):\n","        url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n","        wget.download(url)\n","        !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n","        !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n","        os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n","        !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n","        !cd Tensorflow/models/research/slim && pip install -e . "]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":65760,"status":"ok","timestamp":1650314444526,"user":{"displayName":"Александр","userId":"07878979912285210689"},"user_tz":-180},"id":"5yI5T2lI1Ug9","outputId":"eda48e34-1e32-4367-eff3-a101e54abc33","scrolled":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Running tests under Python 3.7.13: /usr/bin/python3\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","2022-04-18 20:39:45.699506: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","W0418 20:39:46.253355 139674352342912 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 4.57s\n","I0418 20:39:47.061351 139674352342912 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 4.57s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.92s\n","I0418 20:39:47.984033 139674352342912 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.92s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.47s\n","I0418 20:39:48.450056 139674352342912 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.47s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.48s\n","I0418 20:39:48.931178 139674352342912 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.48s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 5.26s\n","I0418 20:39:54.191630 139674352342912 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 5.26s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","I0418 20:39:54.193296 139674352342912 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.05s\n","I0418 20:39:54.243233 139674352342912 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.05s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.08s\n","I0418 20:39:54.325664 139674352342912 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.08s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.05s\n","I0418 20:39:54.373507 139674352342912 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.05s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.35s\n","I0418 20:39:54.727219 139674352342912 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.35s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.44s\n","I0418 20:39:55.168302 139674352342912 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.44s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.46s\n","I0418 20:39:55.625601 139674352342912 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.46s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.38s\n","I0418 20:39:56.010085 139674352342912 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.38s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.32s\n","I0418 20:39:56.331828 139674352342912 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.32s\n","[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.1s\n","I0418 20:39:56.429639 139674352342912 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.1s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","I0418 20:39:57.038528 139674352342912 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0418 20:39:57.038896 139674352342912 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n","I0418 20:39:57.039063 139674352342912 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n","I0418 20:39:57.045482 139674352342912 efficientnet_model.py:144] round_filter input=32 output=32\n","I0418 20:39:57.094749 139674352342912 efficientnet_model.py:144] round_filter input=32 output=32\n","I0418 20:39:57.095041 139674352342912 efficientnet_model.py:144] round_filter input=16 output=16\n","I0418 20:39:57.218501 139674352342912 efficientnet_model.py:144] round_filter input=16 output=16\n","I0418 20:39:57.218693 139674352342912 efficientnet_model.py:144] round_filter input=24 output=24\n","I0418 20:39:57.478760 139674352342912 efficientnet_model.py:144] round_filter input=24 output=24\n","I0418 20:39:57.479068 139674352342912 efficientnet_model.py:144] round_filter input=40 output=40\n","I0418 20:39:57.730637 139674352342912 efficientnet_model.py:144] round_filter input=40 output=40\n","I0418 20:39:57.730889 139674352342912 efficientnet_model.py:144] round_filter input=80 output=80\n","I0418 20:39:58.107983 139674352342912 efficientnet_model.py:144] round_filter input=80 output=80\n","I0418 20:39:58.108293 139674352342912 efficientnet_model.py:144] round_filter input=112 output=112\n","I0418 20:39:58.509566 139674352342912 efficientnet_model.py:144] round_filter input=112 output=112\n","I0418 20:39:58.509853 139674352342912 efficientnet_model.py:144] round_filter input=192 output=192\n","I0418 20:39:59.851382 139674352342912 efficientnet_model.py:144] round_filter input=192 output=192\n","I0418 20:39:59.851697 139674352342912 efficientnet_model.py:144] round_filter input=320 output=320\n","I0418 20:40:00.195779 139674352342912 efficientnet_model.py:144] round_filter input=1280 output=1280\n","I0418 20:40:00.312957 139674352342912 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0418 20:40:00.564170 139674352342912 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n","I0418 20:40:00.564458 139674352342912 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n","I0418 20:40:00.564626 139674352342912 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n","I0418 20:40:00.568483 139674352342912 efficientnet_model.py:144] round_filter input=32 output=32\n","I0418 20:40:00.606151 139674352342912 efficientnet_model.py:144] round_filter input=32 output=32\n","I0418 20:40:00.606428 139674352342912 efficientnet_model.py:144] round_filter input=16 output=16\n","I0418 20:40:01.040925 139674352342912 efficientnet_model.py:144] round_filter input=16 output=16\n","I0418 20:40:01.041205 139674352342912 efficientnet_model.py:144] round_filter input=24 output=24\n","I0418 20:40:01.623729 139674352342912 efficientnet_model.py:144] round_filter input=24 output=24\n","I0418 20:40:01.624042 139674352342912 efficientnet_model.py:144] round_filter input=40 output=40\n","I0418 20:40:02.212369 139674352342912 efficientnet_model.py:144] round_filter input=40 output=40\n","I0418 20:40:02.212697 139674352342912 efficientnet_model.py:144] round_filter input=80 output=80\n","I0418 20:40:02.962799 139674352342912 efficientnet_model.py:144] round_filter input=80 output=80\n","I0418 20:40:02.963115 139674352342912 efficientnet_model.py:144] round_filter input=112 output=112\n","I0418 20:40:03.797224 139674352342912 efficientnet_model.py:144] round_filter input=112 output=112\n","I0418 20:40:03.797509 139674352342912 efficientnet_model.py:144] round_filter input=192 output=192\n","I0418 20:40:05.246174 139674352342912 efficientnet_model.py:144] round_filter input=192 output=192\n","I0418 20:40:05.246498 139674352342912 efficientnet_model.py:144] round_filter input=320 output=320\n","I0418 20:40:05.713885 139674352342912 efficientnet_model.py:144] round_filter input=1280 output=1280\n","I0418 20:40:05.756650 139674352342912 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0418 20:40:05.839337 139674352342912 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n","I0418 20:40:05.839548 139674352342912 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n","I0418 20:40:05.839689 139674352342912 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n","I0418 20:40:05.841860 139674352342912 efficientnet_model.py:144] round_filter input=32 output=32\n","I0418 20:40:05.863047 139674352342912 efficientnet_model.py:144] round_filter input=32 output=32\n","I0418 20:40:05.863243 139674352342912 efficientnet_model.py:144] round_filter input=16 output=16\n","I0418 20:40:06.133358 139674352342912 efficientnet_model.py:144] round_filter input=16 output=16\n","I0418 20:40:06.133645 139674352342912 efficientnet_model.py:144] round_filter input=24 output=24\n","I0418 20:40:07.010449 139674352342912 efficientnet_model.py:144] round_filter input=24 output=24\n","I0418 20:40:07.010747 139674352342912 efficientnet_model.py:144] round_filter input=40 output=48\n","I0418 20:40:07.704326 139674352342912 efficientnet_model.py:144] round_filter input=40 output=48\n","I0418 20:40:07.704654 139674352342912 efficientnet_model.py:144] round_filter input=80 output=88\n","I0418 20:40:08.553807 139674352342912 efficientnet_model.py:144] round_filter input=80 output=88\n","I0418 20:40:08.554167 139674352342912 efficientnet_model.py:144] round_filter input=112 output=120\n","I0418 20:40:09.360039 139674352342912 efficientnet_model.py:144] round_filter input=112 output=120\n","I0418 20:40:09.360335 139674352342912 efficientnet_model.py:144] round_filter input=192 output=208\n","I0418 20:40:10.331875 139674352342912 efficientnet_model.py:144] round_filter input=192 output=208\n","I0418 20:40:10.332200 139674352342912 efficientnet_model.py:144] round_filter input=320 output=352\n","I0418 20:40:10.701094 139674352342912 efficientnet_model.py:144] round_filter input=1280 output=1408\n","I0418 20:40:10.773025 139674352342912 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0418 20:40:10.924098 139674352342912 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n","I0418 20:40:10.924399 139674352342912 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n","I0418 20:40:10.924564 139674352342912 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n","I0418 20:40:10.928986 139674352342912 efficientnet_model.py:144] round_filter input=32 output=40\n","I0418 20:40:10.970759 139674352342912 efficientnet_model.py:144] round_filter input=32 output=40\n","I0418 20:40:10.979108 139674352342912 efficientnet_model.py:144] round_filter input=16 output=24\n","I0418 20:40:11.880306 139674352342912 efficientnet_model.py:144] round_filter input=16 output=24\n","I0418 20:40:11.880644 139674352342912 efficientnet_model.py:144] round_filter input=24 output=32\n","I0418 20:40:12.558334 139674352342912 efficientnet_model.py:144] round_filter input=24 output=32\n","I0418 20:40:12.558662 139674352342912 efficientnet_model.py:144] round_filter input=40 output=48\n","I0418 20:40:12.979823 139674352342912 efficientnet_model.py:144] round_filter input=40 output=48\n","I0418 20:40:12.980145 139674352342912 efficientnet_model.py:144] round_filter input=80 output=96\n","I0418 20:40:14.143620 139674352342912 efficientnet_model.py:144] round_filter input=80 output=96\n","I0418 20:40:14.143856 139674352342912 efficientnet_model.py:144] round_filter input=112 output=136\n","I0418 20:40:15.053628 139674352342912 efficientnet_model.py:144] round_filter input=112 output=136\n","I0418 20:40:15.053887 139674352342912 efficientnet_model.py:144] round_filter input=192 output=232\n","I0418 20:40:16.131744 139674352342912 efficientnet_model.py:144] round_filter input=192 output=232\n","I0418 20:40:16.132003 139674352342912 efficientnet_model.py:144] round_filter input=320 output=384\n","I0418 20:40:16.344815 139674352342912 efficientnet_model.py:144] round_filter input=1280 output=1536\n","I0418 20:40:16.387968 139674352342912 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0418 20:40:16.476716 139674352342912 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n","I0418 20:40:16.476965 139674352342912 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n","I0418 20:40:16.477088 139674352342912 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n","I0418 20:40:16.479189 139674352342912 efficientnet_model.py:144] round_filter input=32 output=48\n","I0418 20:40:16.514975 139674352342912 efficientnet_model.py:144] round_filter input=32 output=48\n","I0418 20:40:16.515196 139674352342912 efficientnet_model.py:144] round_filter input=16 output=24\n","I0418 20:40:16.685523 139674352342912 efficientnet_model.py:144] round_filter input=16 output=24\n","I0418 20:40:16.685748 139674352342912 efficientnet_model.py:144] round_filter input=24 output=32\n","I0418 20:40:17.200998 139674352342912 efficientnet_model.py:144] round_filter input=24 output=32\n","I0418 20:40:17.201223 139674352342912 efficientnet_model.py:144] round_filter input=40 output=56\n","I0418 20:40:17.653598 139674352342912 efficientnet_model.py:144] round_filter input=40 output=56\n","I0418 20:40:17.653856 139674352342912 efficientnet_model.py:144] round_filter input=80 output=112\n","I0418 20:40:18.464777 139674352342912 efficientnet_model.py:144] round_filter input=80 output=112\n","I0418 20:40:18.465014 139674352342912 efficientnet_model.py:144] round_filter input=112 output=160\n","I0418 20:40:19.412106 139674352342912 efficientnet_model.py:144] round_filter input=112 output=160\n","I0418 20:40:19.412332 139674352342912 efficientnet_model.py:144] round_filter input=192 output=272\n","I0418 20:40:20.662114 139674352342912 efficientnet_model.py:144] round_filter input=192 output=272\n","I0418 20:40:20.662422 139674352342912 efficientnet_model.py:144] round_filter input=320 output=448\n","I0418 20:40:21.046286 139674352342912 efficientnet_model.py:144] round_filter input=1280 output=1792\n","I0418 20:40:21.114801 139674352342912 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0418 20:40:21.730144 139674352342912 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n","I0418 20:40:21.730462 139674352342912 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n","I0418 20:40:21.730642 139674352342912 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n","I0418 20:40:21.735325 139674352342912 efficientnet_model.py:144] round_filter input=32 output=48\n","I0418 20:40:21.776452 139674352342912 efficientnet_model.py:144] round_filter input=32 output=48\n","I0418 20:40:21.776755 139674352342912 efficientnet_model.py:144] round_filter input=16 output=24\n","I0418 20:40:22.235565 139674352342912 efficientnet_model.py:144] round_filter input=16 output=24\n","I0418 20:40:22.235842 139674352342912 efficientnet_model.py:144] round_filter input=24 output=40\n","I0418 20:40:22.863788 139674352342912 efficientnet_model.py:144] round_filter input=24 output=40\n","I0418 20:40:22.864026 139674352342912 efficientnet_model.py:144] round_filter input=40 output=64\n","I0418 20:40:23.663323 139674352342912 efficientnet_model.py:144] round_filter input=40 output=64\n","I0418 20:40:23.663544 139674352342912 efficientnet_model.py:144] round_filter input=80 output=128\n","I0418 20:40:24.676721 139674352342912 efficientnet_model.py:144] round_filter input=80 output=128\n","I0418 20:40:24.676957 139674352342912 efficientnet_model.py:144] round_filter input=112 output=176\n","I0418 20:40:25.593818 139674352342912 efficientnet_model.py:144] round_filter input=112 output=176\n","I0418 20:40:25.594059 139674352342912 efficientnet_model.py:144] round_filter input=192 output=304\n","I0418 20:40:26.961430 139674352342912 efficientnet_model.py:144] round_filter input=192 output=304\n","I0418 20:40:26.961750 139674352342912 efficientnet_model.py:144] round_filter input=320 output=512\n","I0418 20:40:27.598848 139674352342912 efficientnet_model.py:144] round_filter input=1280 output=2048\n","I0418 20:40:27.674190 139674352342912 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0418 20:40:27.932825 139674352342912 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n","I0418 20:40:27.933183 139674352342912 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n","I0418 20:40:27.933350 139674352342912 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n","I0418 20:40:27.937973 139674352342912 efficientnet_model.py:144] round_filter input=32 output=56\n","I0418 20:40:27.975861 139674352342912 efficientnet_model.py:144] round_filter input=32 output=56\n","I0418 20:40:27.976184 139674352342912 efficientnet_model.py:144] round_filter input=16 output=32\n","I0418 20:40:28.276857 139674352342912 efficientnet_model.py:144] round_filter input=16 output=32\n","I0418 20:40:28.277060 139674352342912 efficientnet_model.py:144] round_filter input=24 output=40\n","I0418 20:40:28.922228 139674352342912 efficientnet_model.py:144] round_filter input=24 output=40\n","I0418 20:40:28.922471 139674352342912 efficientnet_model.py:144] round_filter input=40 output=72\n","I0418 20:40:29.570105 139674352342912 efficientnet_model.py:144] round_filter input=40 output=72\n","I0418 20:40:29.570327 139674352342912 efficientnet_model.py:144] round_filter input=80 output=144\n","I0418 20:40:30.458742 139674352342912 efficientnet_model.py:144] round_filter input=80 output=144\n","I0418 20:40:30.458979 139674352342912 efficientnet_model.py:144] round_filter input=112 output=200\n","I0418 20:40:32.479396 139674352342912 efficientnet_model.py:144] round_filter input=112 output=200\n","I0418 20:40:32.479607 139674352342912 efficientnet_model.py:144] round_filter input=192 output=344\n","I0418 20:40:33.664772 139674352342912 efficientnet_model.py:144] round_filter input=192 output=344\n","I0418 20:40:33.665035 139674352342912 efficientnet_model.py:144] round_filter input=320 output=576\n","I0418 20:40:33.982297 139674352342912 efficientnet_model.py:144] round_filter input=1280 output=2304\n","I0418 20:40:34.021029 139674352342912 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0418 20:40:34.145715 139674352342912 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n","I0418 20:40:34.145934 139674352342912 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n","I0418 20:40:34.146082 139674352342912 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n","I0418 20:40:34.149291 139674352342912 efficientnet_model.py:144] round_filter input=32 output=64\n","I0418 20:40:34.169521 139674352342912 efficientnet_model.py:144] round_filter input=32 output=64\n","I0418 20:40:34.169718 139674352342912 efficientnet_model.py:144] round_filter input=16 output=32\n","I0418 20:40:34.533157 139674352342912 efficientnet_model.py:144] round_filter input=16 output=32\n","I0418 20:40:34.533369 139674352342912 efficientnet_model.py:144] round_filter input=24 output=48\n","I0418 20:40:35.305630 139674352342912 efficientnet_model.py:144] round_filter input=24 output=48\n","I0418 20:40:35.305906 139674352342912 efficientnet_model.py:144] round_filter input=40 output=80\n","I0418 20:40:36.080593 139674352342912 efficientnet_model.py:144] round_filter input=40 output=80\n","I0418 20:40:36.080806 139674352342912 efficientnet_model.py:144] round_filter input=80 output=160\n","I0418 20:40:37.158864 139674352342912 efficientnet_model.py:144] round_filter input=80 output=160\n","I0418 20:40:37.159108 139674352342912 efficientnet_model.py:144] round_filter input=112 output=224\n","I0418 20:40:38.239438 139674352342912 efficientnet_model.py:144] round_filter input=112 output=224\n","I0418 20:40:38.239660 139674352342912 efficientnet_model.py:144] round_filter input=192 output=384\n","I0418 20:40:39.655308 139674352342912 efficientnet_model.py:144] round_filter input=192 output=384\n","I0418 20:40:39.655519 139674352342912 efficientnet_model.py:144] round_filter input=320 output=640\n","I0418 20:40:40.434035 139674352342912 efficientnet_model.py:144] round_filter input=1280 output=2560\n","I0418 20:40:40.483471 139674352342912 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 44.22s\n","I0418 20:40:40.658637 139674352342912 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 44.22s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","I0418 20:40:40.667150 139674352342912 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","I0418 20:40:40.669312 139674352342912 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","I0418 20:40:40.670004 139674352342912 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","I0418 20:40:40.671962 139674352342912 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTF2Test.test_session\n","[  SKIPPED ] ModelBuilderTF2Test.test_session\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","I0418 20:40:40.673790 139674352342912 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","I0418 20:40:40.674443 139674352342912 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","I0418 20:40:40.675714 139674352342912 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 24 tests in 58.190s\n","\n","OK (skipped=1)\n"]}],"source":["# Проверяем все ли установилось правильно\n","# Обычно для корректной работы необходимо доустановить некоторые библиотеки\n","# Но лучше использовать Google colab \n","\n","VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n","\n","!python {VERIFICATION_SCRIPT}"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1650314445557,"user":{"displayName":"Александр","userId":"07878979912285210689"},"user_tz":-180},"id":"kKa-8a_l1Ug-"},"outputs":[],"source":["# Проверяем установку Object detection\n","import object_detection"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1431,"status":"ok","timestamp":1650314475967,"user":{"displayName":"Александр","userId":"07878979912285210689"},"user_tz":-180},"id":"csofht2npfDE","outputId":"391dd17a-c8fa-48da-869b-2265076e2f3e"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-04-18 20:41:12--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 142.250.159.128, 2607:f8b0:4001:c1f::80\n","Connecting to download.tensorflow.org (download.tensorflow.org)|142.250.159.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 20518283 (20M) [application/x-tar]\n","Saving to: ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz’\n","\n","ssd_mobilenet_v2_fp 100%[===================>]  19.57M   119MB/s    in 0.2s    \n","\n","2022-04-18 20:41:13 (119 MB/s) - ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz’ saved [20518283/20518283]\n","\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/checkpoint\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/pipeline.config\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/saved_model.pb\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"]}],"source":["# Скачиваем модель и разархивируем её\n","if os.name =='posix':\n","    !wget {PRETRAINED_MODEL_URL}\n","    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n","    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n","if os.name == 'nt':\n","    wget.download(PRETRAINED_MODEL_URL)\n","    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n","    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"]},{"cell_type":"markdown","metadata":{"id":"M5KJTnkfpfDC"},"source":["## 2. Создаем метки"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":304,"status":"ok","timestamp":1650314507188,"user":{"displayName":"Александр","userId":"07878979912285210689"},"user_tz":-180},"id":"p1BVDWo7pfDC"},"outputs":[],"source":["labels = [{'name':'number', 'id':1}]\n","\n","with open(files['LABELMAP'], 'w') as f:\n","    for label in labels:\n","        f.write('item { \\n')\n","        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n","        f.write('\\tid:{}\\n'.format(label['id']))\n","        f.write('}\\n')"]},{"cell_type":"markdown","metadata":{"id":"C88zyVELpfDC"},"source":["## 3. Преобразуем данные в читаемый формат для модели (TF records)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":389,"status":"ok","timestamp":1650314596246,"user":{"displayName":"Александр","userId":"07878979912285210689"},"user_tz":-180},"id":"KWpb_BVUpfDD","outputId":"eb80ec94-c889-4730-c51e-0e0f16da9e35"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Tensorflow/scripts'...\n","remote: Enumerating objects: 3, done.\u001b[K\n","remote: Counting objects:  33% (1/3)\u001b[K\rremote: Counting objects:  66% (2/3)\u001b[K\rremote: Counting objects: 100% (3/3)\u001b[K\rremote: Counting objects: 100% (3/3), done.\u001b[K\n","remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n","remote: Total 3 (delta 0), reused 1 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects:  33% (1/3)   \rUnpacking objects:  66% (2/3)   \rUnpacking objects: 100% (3/3)   \rUnpacking objects: 100% (3/3), done.\n"]}],"source":["## Используем готовый рекомендуемый скрипт для преобразования формата\n","if not os.path.exists(files['TF_RECORD_SCRIPT']):\n","    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8084,"status":"ok","timestamp":1650314623829,"user":{"displayName":"Александр","userId":"07878979912285210689"},"user_tz":-180},"id":"UPFToGZqpfDD","outputId":"baa9c423-02a2-4dfb-9182-accfdd3b6ad9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully created the TFRecord file: Tensorflow/workspace/annotations/train.record\n","Successfully created the TFRecord file: Tensorflow/workspace/annotations/test.record\n"]}],"source":["!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n","!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "]},{"cell_type":"markdown","metadata":{"id":"qT4QU7pLpfDE"},"source":["## 4. Скопируем модель в рабочую директорию"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":312,"status":"ok","timestamp":1650314657519,"user":{"displayName":"Александр","userId":"07878979912285210689"},"user_tz":-180},"id":"cOjuTFbwpfDF"},"outputs":[],"source":["if os.name =='posix':\n","    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n","if os.name == 'nt':\n","    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"]},{"cell_type":"markdown","metadata":{"id":"Ga8gpNslpfDF"},"source":["## 5. Обновим конфигурационный файл для трансферного обучения\n","\n","Основное это указать карту меток и указать путь к каталогом с размечеными файлами в формате TFRecord"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":3593,"status":"ok","timestamp":1650314750306,"user":{"displayName":"Александр","userId":"07878979912285210689"},"user_tz":-180},"id":"Z9hRrO_ppfDF"},"outputs":[],"source":["import tensorflow as tf\n","from object_detection.utils import config_util\n","from object_detection.protos import pipeline_pb2\n","from google.protobuf import text_format"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1650314750307,"user":{"displayName":"Александр","userId":"07878979912285210689"},"user_tz":-180},"id":"c2A0mn4ipfDF"},"outputs":[],"source":["config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1650314750310,"user":{"displayName":"Александр","userId":"07878979912285210689"},"user_tz":-180},"id":"uQA13-afpfDF","outputId":"3281105a-a4e8-44cb-b600-30a43f98d2c6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'eval_config': metrics_set: \"coco_detection_metrics\"\n"," use_moving_averages: false,\n"," 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n"," shuffle: false\n"," num_epochs: 1\n"," tf_record_input_reader {\n","   input_path: \"PATH_TO_BE_CONFIGURED\"\n"," },\n"," 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n"," shuffle: false\n"," num_epochs: 1\n"," tf_record_input_reader {\n","   input_path: \"PATH_TO_BE_CONFIGURED\"\n"," }\n"," ],\n"," 'model': ssd {\n","   num_classes: 90\n","   image_resizer {\n","     fixed_shape_resizer {\n","       height: 640\n","       width: 640\n","     }\n","   }\n","   feature_extractor {\n","     type: \"ssd_mobilenet_v2_fpn_keras\"\n","     depth_multiplier: 1.0\n","     min_depth: 16\n","     conv_hyperparams {\n","       regularizer {\n","         l2_regularizer {\n","           weight: 3.9999998989515007e-05\n","         }\n","       }\n","       initializer {\n","         random_normal_initializer {\n","           mean: 0.0\n","           stddev: 0.009999999776482582\n","         }\n","       }\n","       activation: RELU_6\n","       batch_norm {\n","         decay: 0.996999979019165\n","         scale: true\n","         epsilon: 0.0010000000474974513\n","       }\n","     }\n","     use_depthwise: true\n","     override_base_feature_extractor_hyperparams: true\n","     fpn {\n","       min_level: 3\n","       max_level: 7\n","       additional_layer_depth: 128\n","     }\n","   }\n","   box_coder {\n","     faster_rcnn_box_coder {\n","       y_scale: 10.0\n","       x_scale: 10.0\n","       height_scale: 5.0\n","       width_scale: 5.0\n","     }\n","   }\n","   matcher {\n","     argmax_matcher {\n","       matched_threshold: 0.5\n","       unmatched_threshold: 0.5\n","       ignore_thresholds: false\n","       negatives_lower_than_unmatched: true\n","       force_match_for_each_row: true\n","       use_matmul_gather: true\n","     }\n","   }\n","   similarity_calculator {\n","     iou_similarity {\n","     }\n","   }\n","   box_predictor {\n","     weight_shared_convolutional_box_predictor {\n","       conv_hyperparams {\n","         regularizer {\n","           l2_regularizer {\n","             weight: 3.9999998989515007e-05\n","           }\n","         }\n","         initializer {\n","           random_normal_initializer {\n","             mean: 0.0\n","             stddev: 0.009999999776482582\n","           }\n","         }\n","         activation: RELU_6\n","         batch_norm {\n","           decay: 0.996999979019165\n","           scale: true\n","           epsilon: 0.0010000000474974513\n","         }\n","       }\n","       depth: 128\n","       num_layers_before_predictor: 4\n","       kernel_size: 3\n","       class_prediction_bias_init: -4.599999904632568\n","       share_prediction_tower: true\n","       use_depthwise: true\n","     }\n","   }\n","   anchor_generator {\n","     multiscale_anchor_generator {\n","       min_level: 3\n","       max_level: 7\n","       anchor_scale: 4.0\n","       aspect_ratios: 1.0\n","       aspect_ratios: 2.0\n","       aspect_ratios: 0.5\n","       scales_per_octave: 2\n","     }\n","   }\n","   post_processing {\n","     batch_non_max_suppression {\n","       score_threshold: 9.99999993922529e-09\n","       iou_threshold: 0.6000000238418579\n","       max_detections_per_class: 100\n","       max_total_detections: 100\n","       use_static_shapes: false\n","     }\n","     score_converter: SIGMOID\n","   }\n","   normalize_loss_by_num_matches: true\n","   loss {\n","     localization_loss {\n","       weighted_smooth_l1 {\n","       }\n","     }\n","     classification_loss {\n","       weighted_sigmoid_focal {\n","         gamma: 2.0\n","         alpha: 0.25\n","       }\n","     }\n","     classification_weight: 1.0\n","     localization_weight: 1.0\n","   }\n","   encode_background_as_zeros: true\n","   normalize_loc_loss_by_codesize: true\n","   inplace_batchnorm_update: true\n","   freeze_batchnorm: false\n"," },\n"," 'train_config': batch_size: 128\n"," data_augmentation_options {\n","   random_horizontal_flip {\n","   }\n"," }\n"," data_augmentation_options {\n","   random_crop_image {\n","     min_object_covered: 0.0\n","     min_aspect_ratio: 0.75\n","     max_aspect_ratio: 3.0\n","     min_area: 0.75\n","     max_area: 1.0\n","     overlap_thresh: 0.0\n","   }\n"," }\n"," sync_replicas: true\n"," optimizer {\n","   momentum_optimizer {\n","     learning_rate {\n","       cosine_decay_learning_rate {\n","         learning_rate_base: 0.07999999821186066\n","         total_steps: 50000\n","         warmup_learning_rate: 0.026666000485420227\n","         warmup_steps: 1000\n","       }\n","     }\n","     momentum_optimizer_value: 0.8999999761581421\n","   }\n","   use_moving_average: false\n"," }\n"," fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n"," num_steps: 50000\n"," startup_delay_steps: 0.0\n"," replicas_to_aggregate: 8\n"," max_number_of_boxes: 100\n"," unpad_groundtruth_tensors: false\n"," fine_tune_checkpoint_type: \"classification\"\n"," fine_tune_checkpoint_version: V2,\n"," 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n"," tf_record_input_reader {\n","   input_path: \"PATH_TO_BE_CONFIGURED\"\n"," }}"]},"metadata":{},"execution_count":28}],"source":["config"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1650314750311,"user":{"displayName":"Александр","userId":"07878979912285210689"},"user_tz":-180},"id":"9vK5lotDpfDF"},"outputs":[],"source":["pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n","with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n","    proto_str = f.read()                                                                                                                                                                                                                                          \n","    text_format.Merge(proto_str, pipeline_config)  "]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1650314751134,"user":{"displayName":"Александр","userId":"07878979912285210689"},"user_tz":-180},"id":"rP43Ph0JpfDG"},"outputs":[],"source":["pipeline_config.model.ssd.num_classes = len(labels)\n","pipeline_config.train_config.batch_size = 8\n","pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n","pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n","pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n","pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n","pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n","pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1650314751830,"user":{"displayName":"Александр","userId":"07878979912285210689"},"user_tz":-180},"id":"oJvfgwWqpfDG","outputId":"897e5be6-283c-4148-fdac-b2c86bb04b51"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tensorflow/workspace/models/my_ssd_mobilenet/pipeline.config\n"]}],"source":["config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n","with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:  \n","    print(files['PIPELINE_CONFIG'])\n","    f.write(config_text)   "]},{"cell_type":"markdown","metadata":{"id":"Zr3ON7xMpfDG"},"source":["## 6. Обучение модели"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B-Y2UQmQpfDG"},"outputs":[],"source":["TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jMP2XDfQpfDH"},"outputs":[],"source":["command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=10000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i3ZsJR-qpfDH"},"outputs":[],"source":["!{command}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"32SvEYUw2mKP"},"outputs":[],"source":["!pip uninstall opencv-python-headless==4.5.5.62"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nXb8N-Rv2uVR"},"outputs":[],"source":["!pip install opencv-python-headless==4.1.2.30"]},{"cell_type":"markdown","source":["## 7. Загрузка готовой модели"],"metadata":{"id":"U8cJp04JbnSU"}},{"cell_type":"code","execution_count":33,"metadata":{"id":"8TYk4_oIpfDI","executionInfo":{"status":"ok","timestamp":1650314937559,"user_tz":-180,"elapsed":345,"user":{"displayName":"Александр","userId":"07878979912285210689"}}},"outputs":[],"source":["import os\n","import tensorflow as tf\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder\n","from object_detection.utils import config_util"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tDnQg-cYpfDI"},"outputs":[],"source":["# Загрузка модели и конфигурации\n","configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n","detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n","\n","# Загрузка chekpoint с обучеными весами\n","ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n","ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-5')).expect_partial()\n","\n","@tf.function\n","def detect_fn(image):\n","    image, shapes = detection_model.preprocess(image)\n","    prediction_dict = detection_model.predict(image, shapes)\n","    detections = detection_model.postprocess(prediction_dict, shapes)\n","    return detections"]},{"cell_type":"markdown","metadata":{"id":"0EmsmbBZpfDI"},"source":["# 9. Детектирование изображения"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y_MKiuZ4pfDI"},"outputs":[],"source":["import cv2 \n","import numpy as np\n","from matplotlib import pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cBDbIhNapfDI"},"outputs":[],"source":["category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lx3crOhOzITB"},"outputs":[],"source":["IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'livelong.02533422-940e-11eb-9dbd-5cf3709bbcc6.jpg')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tpzn1SMry1yK"},"outputs":[],"source":["img = cv2.imread(IMAGE_PATH)\n","image_np = np.array(img)\n","\n","input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n","detections = detect_fn(input_tensor)\n","\n","num_detections = int(detections.pop('num_detections'))\n","detections = {key: value[0, :num_detections].numpy()\n","              for key, value in detections.items()}\n","detections['num_detections'] = num_detections\n","\n","# detection_classes should be ints.\n","detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","label_id_offset = 1\n","image_np_with_detections = image_np.copy()\n","\n","viz_utils.visualize_boxes_and_labels_on_image_array(\n","            image_np_with_detections,\n","            detections['detection_boxes'],\n","            detections['detection_classes']+label_id_offset,\n","            detections['detection_scores'],\n","            category_index,\n","            use_normalized_coordinates=True,\n","            max_boxes_to_draw=5,\n","            min_score_thresh=.8,\n","            agnostic_mode=False)\n","\n","plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"IsNAaYAo0WVL"},"source":["# 10. Real Time Detections from your Webcam"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5CYeKcUm1UhE"},"outputs":[],"source":["!pip uninstall opencv-python-headless -y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o_grs6OGpfDJ"},"outputs":[],"source":["cap = cv2.VideoCapture(0)\n","width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","while cap.isOpened(): \n","    ret, frame = cap.read()\n","    image_np = np.array(frame)\n","    \n","    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n","    detections = detect_fn(input_tensor)\n","    \n","    num_detections = int(detections.pop('num_detections'))\n","    detections = {key: value[0, :num_detections].numpy()\n","                  for key, value in detections.items()}\n","    detections['num_detections'] = num_detections\n","\n","    # detection_classes should be ints.\n","    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","    label_id_offset = 1\n","    image_np_with_detections = image_np.copy()\n","\n","    viz_utils.visualize_boxes_and_labels_on_image_array(\n","                image_np_with_detections,\n","                detections['detection_boxes'],\n","                detections['detection_classes']+label_id_offset,\n","                detections['detection_scores'],\n","                category_index,\n","                use_normalized_coordinates=True,\n","                max_boxes_to_draw=5,\n","                min_score_thresh=.8,\n","                agnostic_mode=False)\n","\n","    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n","    \n","    if cv2.waitKey(10) & 0xFF == ord('q'):\n","        cap.release()\n","        cv2.destroyAllWindows()\n","        break"]},{"cell_type":"markdown","metadata":{"id":"rzlM4jt0pfDJ"},"source":["# 10. Freezing the Graph"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n4olHB2npfDJ"},"outputs":[],"source":["FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0AjO93QDpfDJ"},"outputs":[],"source":["command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F6Lsp3tCpfDJ"},"outputs":[],"source":["print(command)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Sw1ULgHpfDJ"},"outputs":[],"source":["!{command}"]},{"cell_type":"markdown","metadata":{"id":"wTPmdqaXpfDK"},"source":["# 11. Conversion to TFJS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gZ6UzY_fpfDK","scrolled":true},"outputs":[],"source":["!pip install tensorflowjs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0oxbVynHpfDK"},"outputs":[],"source":["command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DB2AGNmJpfDK"},"outputs":[],"source":["print(command)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K7rfT4-hpfDK"},"outputs":[],"source":["!{command}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o8_hm-itpfDK"},"outputs":[],"source":["# Test Code: https://github.com/nicknochnack/RealTimeSignLanguageDetectionwithTFJS"]},{"cell_type":"markdown","metadata":{"id":"VtUw73FHpfDK"},"source":["# 12. Conversion to TFLite"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XviMtewLpfDK"},"outputs":[],"source":["TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"us86cjC4pfDL"},"outputs":[],"source":["command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n1r5YO3rpfDL"},"outputs":[],"source":["print(command)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I-xWpHN8pfDL"},"outputs":[],"source":["!{command}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iJfYMbN6pfDL"},"outputs":[],"source":["FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n","TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OAJPxhXT1UhG"},"outputs":[],"source":["command = \"tflite_convert \\\n","--saved_model_dir={} \\\n","--output_file={} \\\n","--input_shapes=1,300,300,3 \\\n","--input_arrays=normalized_input_image_tensor \\\n","--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n","--inference_type=FLOAT \\\n","--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E8GwUeoFpfDL"},"outputs":[],"source":["print(command)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nbd7gqHMpfDL"},"outputs":[],"source":["!{command}"]},{"cell_type":"markdown","metadata":{"id":"5NQqZRdA21Uc"},"source":["# 13. Zip and Export Models "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tTVTGCQp2ZJJ"},"outputs":[],"source":["!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"whShhB0x3PYJ"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]}],"metadata":{"accelerator":"GPU","colab":{"name":"2. Training and Detection.ipynb","provenance":[],"collapsed_sections":["IsNAaYAo0WVL","rzlM4jt0pfDJ","wTPmdqaXpfDK","VtUw73FHpfDK","5NQqZRdA21Uc"]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":0}